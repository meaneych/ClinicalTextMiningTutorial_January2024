Clinical Text Mining: A Showcase of Computational Tools and Statistical Models in R/Python

Author: Christopher Meaney

Date: January 2024

Healthcare systems are collecting increasingly large quantities of digital information on their patients; much of the digital health information generated exists in clinical text format. The objective of this talk/tutorial is to introduce several computational tools and statistical models commonly encountered in clinical text mining research. The talk begins by introducing how text/string data (i.e. collections of digital character sequences) are stored in R/Python, and how they might be manipulated using pattern matching and regular expression algorithms. Next, the talk introduces the problem of tokenization, i.e. splitting input digital character sequences into sets of words/tokens (several tokenizers are introduced and empirically compared). Statistical semantic models are introduced (document term matrices, term co-occurrence matrices, etc.), and we illustrate how they can be used in several diverse clinical NLP problems (e.g. supervised document classification, unsupervised topic extraction and document clustering, unsupervised token/word clustering, etc.). Lastly, the talk introduces large language models (LLMs), as a general purpose and performant class of statistical model across a variety of core clinical NLP tasks (with particular application to clinical text deidentification, cast as a named entity recognition problem). Jupyter notebooks (using either R/Python kernels) will be provided to illustrate computational tools and statistical models introduced in the talk, and are available at the following URL: https://github.com/meaneych/ClinicalTextMiningTutorial_January2024


